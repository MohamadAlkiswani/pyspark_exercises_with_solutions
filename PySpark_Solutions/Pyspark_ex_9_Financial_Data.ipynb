{"cells":[{"cell_type":"markdown","metadata":{"id":"Z7mnW0U-l54c"},"source":["# Getting Financial Data - Pandas Datareader"]},{"cell_type":"markdown","metadata":{"id":"_GBV6A27l54g"},"source":["### Introduction:\n","\n","This time you will get data from a website.\n","\n","\n","### Step 1. Import the necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"WKoHyj8al54h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713215647884,"user_tz":-120,"elapsed":58901,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"116841b1-f5d6-4dcc-90dc-21c2e5c91682"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=6efc936a6edc23be481a6fae44723a3345a7b3b88c606e6551043e5b19cbc744\n","  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.1\n"]}],"source":["!pip install pyspark"]},{"cell_type":"code","source":["import pyspark.sql.functions as F\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import IntegerType, FloatType\n","from pyspark.sql.functions import expr, col, mean, when, sum, count, desc, min, max"],"metadata":{"id":"U0hF1X-hm0aO","executionInfo":{"status":"ok","timestamp":1713215647885,"user_tz":-120,"elapsed":13,"user":{"displayName":"Ki","userId":"11929899752149255490"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"metadata":{"id":"97yGr09dm10p","executionInfo":{"status":"ok","timestamp":1713215675184,"user_tz":-120,"elapsed":8154,"user":{"displayName":"Ki","userId":"11929899752149255490"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XVAISgGNl54i"},"source":["### Step 2. Create your time range (start and end variables). The start date should be 01/01/2015 and the end should today (whatever your today is)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjPXV31gl54j"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7HswCSNBl54j"},"source":["### Step 3. Get an API key for one of the APIs that are supported by Pandas Datareader, preferably for AlphaVantage.\n","\n","If you do not have an API key for any of the supported APIs, it is easiest to get one for [AlphaVantage](https://www.alphavantage.co/support/#api-key). (Note that the API key is shown directly after the signup. You do *not* receive it via e-mail.)\n","\n","(For a full list of the APIs that are supported by Pandas Datareader, [see here](https://pydata.github.io/pandas-datareader/readers/index.html). As the APIs are provided by third parties, this list may change.)"]},{"cell_type":"markdown","metadata":{"id":"uTJ5A85-l54k"},"source":["### Step 4. Use Pandas Datarader to read the daily time series for the Apple stock (ticker symbol AAPL) between 01/01/2015 and today, assign it to df_apple and print it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99e-24oal54k"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"hH7HfK-Zl54l"},"source":["### Step 5. Add a new column \"stock\" to the dataframe and add the ticker symbol"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RY1eKJu7l54l"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"FZPP5Fmkl54l"},"source":["### Step 6. Repeat the two previous steps for a few other stocks, always creating a new dataframe: Tesla, IBM and Microsoft. (Ticker symbols TSLA, IBM and MSFT.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F12yW4bYl54l"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"aZqv0iNYl54l"},"source":["### Step 7. Combine the four separate dataFrames into one combined dataFrame df that holds the information for all four stocks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V3w6Mgdkl54m"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5BmWwk-Xl54m"},"source":["### Step 8. Shift the stock column into the index (making it a multi-level index consisting of the ticker symbol and the date)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtH7DRAml54m"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Zg9pEchdl54m"},"source":["### Step 7. Create a dataFrame called vol, with the volume values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bXtPCrVAl54m"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"U79ej766l54m"},"source":["### Step 8. Aggregate the data of volume to weekly.\n","Hint: Be careful to not sum data from the same week of 2015 and other years."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W8ImHIobl54n"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"VYHZLEtbl54n"},"source":["### Step 9. Find all the volume traded in the year of 2015"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzW_Vp6Ll54n"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[{"file_id":"https://github.com/areibman/pyspark_exercises/blob/master/09_Time_Series/Getting_Financial_Data/Exercises.ipynb","timestamp":1713215562932}]}},"nbformat":4,"nbformat_minor":0}