{"cells":[{"cell_type":"markdown","metadata":{"id":"bfyfnvnzRqXp"},"source":["# Fictitious Names"]},{"cell_type":"markdown","metadata":{"id":"MQeuVhGTRqXq"},"source":["### Introduction:\n","\n","This time you will create a data again\n","\n","Special thanks to [Chris Albon](http://chrisalbon.com/) for sharing the dataset and materials.\n","All the credits to this exercise belongs to him.  \n","\n","In order to understand about it go [here](https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/).\n","\n","### Step 1. Import the necessary libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFONfNfwRqXs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712841061929,"user_tz":-120,"elapsed":66670,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"7cf2d4c7-15d4-4a07-bad9-1b81dd8dd330"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=f985dcc14ce707bf0addf7d16ee4f6ee836fcc93b7b27b7d396a0a3c1c51533e\n","  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.1\n"]}],"source":["!pip install pyspark"]},{"cell_type":"code","source":["import pyspark.sql.functions as F\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import IntegerType, FloatType\n","from pyspark.sql.functions import expr, col, mean, when, sum, count, desc, min, max\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"metadata":{"id":"SzttAGrBR1Zm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tKdUNDTLRqXt"},"source":["### Step 2. Create the 3 DataFrames based on the following raw data"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"4lUxXG8KRqXt"},"outputs":[],"source":["raw_data_1 = {\n","        'subject_id': ['1', '2', '3', '4', '5'],\n","        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n","        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n","\n","raw_data_2 = {\n","        'subject_id': ['4', '5', '6', '7', '8'],\n","        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n","        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n","\n","raw_data_3 = {\n","        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n","        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}"]},{"cell_type":"markdown","metadata":{"id":"YY_tzYc6RqXu"},"source":["### Step 3. Assign each to a variable called data1, data2, data3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsuD67cNRqXu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712842652814,"user_tz":-120,"elapsed":7764,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"f1054f11-0227-45c2-a213-13cac13b1355"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+----------+---------+\n","|subject_id|first_name|last_name|\n","+----------+----------+---------+\n","|         1|      Alex| Anderson|\n","|         2|       Amy| Ackerman|\n","|         3|     Allen|      Ali|\n","|         4|     Alice|     Aoni|\n","|         5|    Ayoung|  Atiches|\n","+----------+----------+---------+\n","\n"]}],"source":["data1 = spark.createDataFrame(zip(*raw_data_1.values()), list(raw_data_1.keys()))\n","data1.show(5)"]},{"cell_type":"code","source":["data2 = spark.createDataFrame(zip(*raw_data_2.values()), list(raw_data_2.keys()))\n","data2.show(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ixb3STdmYCfe","executionInfo":{"status":"ok","timestamp":1712842654493,"user_tz":-120,"elapsed":1168,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"a167100f-1667-44b8-9155-5ed73a2d2496"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+----------+---------+\n","|subject_id|first_name|last_name|\n","+----------+----------+---------+\n","|         4|     Billy|   Bonder|\n","|         5|     Brian|    Black|\n","|         6|      Bran|  Balwner|\n","|         7|     Bryce|    Brice|\n","|         8|     Betty|   Btisan|\n","+----------+----------+---------+\n","\n"]}]},{"cell_type":"code","source":["data3 = spark.createDataFrame(zip(*raw_data_3.values()), list(raw_data_3.keys()))\n","data3.show(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMkaQyHKYE5K","executionInfo":{"status":"ok","timestamp":1712842656941,"user_tz":-120,"elapsed":926,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"0e894bf8-783e-4ae7-d327-0db8372fbcb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-------+\n","|subject_id|test_id|\n","+----------+-------+\n","|         1|     51|\n","|         2|     15|\n","|         3|     15|\n","|         4|     61|\n","|         5|     16|\n","+----------+-------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"pznSA9SXRqXu"},"source":["### Step 4. Join the two dataframes along rows and assign all_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zh83xNqRRqXu"},"outputs":[],"source":["all_data = data1.union(data2)"]},{"cell_type":"code","source":["all_data.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbpkCyVjZA--","executionInfo":{"status":"ok","timestamp":1712842877199,"user_tz":-120,"elapsed":1259,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"e948a618-9ebb-498b-aba6-f9d79386fc60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+----------+---------+\n","|subject_id|first_name|last_name|\n","+----------+----------+---------+\n","|         1|      Alex| Anderson|\n","|         2|       Amy| Ackerman|\n","|         3|     Allen|      Ali|\n","|         4|     Alice|     Aoni|\n","|         5|    Ayoung|  Atiches|\n","|         4|     Billy|   Bonder|\n","|         5|     Brian|    Black|\n","|         6|      Bran|  Balwner|\n","|         7|     Bryce|    Brice|\n","|         8|     Betty|   Btisan|\n","+----------+----------+---------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"z6KxA17CRqXu"},"source":["### Step 5. Join the two dataframes along columns and assing to all_data_col"]},{"cell_type":"markdown","metadata":{"id":"S0yWG-16RqXu"},"source":["### Step 6. Print data3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pcZd-RfRqXu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712843158967,"user_tz":-120,"elapsed":513,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"964f1a25-48f9-43e7-d622-ab9d9487aa62"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-------+\n","|subject_id|test_id|\n","+----------+-------+\n","|         1|     51|\n","|         2|     15|\n","|         3|     15|\n","|         4|     61|\n","|         5|     16|\n","|         7|     14|\n","|         8|     15|\n","|         9|      1|\n","|        10|     61|\n","|        11|     16|\n","+----------+-------+\n","\n"]}],"source":["data3.show()"]},{"cell_type":"markdown","metadata":{"id":"LuoAvcPZRqXv"},"source":["### Step 7. Merge all_data and data3 along the subject_id value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wrJjLC4yRqXv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712843210558,"user_tz":-120,"elapsed":3837,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"e358010d-33fc-45d2-87a0-50f3eeca7514"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+----------+---------+----------+-------+\n","|subject_id|first_name|last_name|subject_id|test_id|\n","+----------+----------+---------+----------+-------+\n","|         1|      Alex| Anderson|         1|     51|\n","|         2|       Amy| Ackerman|         2|     15|\n","|         3|     Allen|      Ali|         3|     15|\n","|         4|     Alice|     Aoni|         4|     61|\n","|         4|     Billy|   Bonder|         4|     61|\n","|         5|    Ayoung|  Atiches|         5|     16|\n","|         5|     Brian|    Black|         5|     16|\n","|         7|     Bryce|    Brice|         7|     14|\n","|         8|     Betty|   Btisan|         8|     15|\n","+----------+----------+---------+----------+-------+\n","\n"]}],"source":["all_data = all_data.join(data3, all_data.subject_id == data3.subject_id)\n","all_data.show()"]},{"cell_type":"markdown","metadata":{"id":"U-D1d50MRqXv"},"source":["### Step 8. Merge only the data that has the same 'subject_id' on both data1 and data2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7-94OSo2RqXv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712843695109,"user_tz":-120,"elapsed":2055,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"f1f1b4ca-ab4d-40cd-cf86-d70e1cf95c8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+----------+---------+----------+----------+---------+\n","|subject_id|first_name|last_name|subject_id|first_name|last_name|\n","+----------+----------+---------+----------+----------+---------+\n","|         4|     Alice|     Aoni|         4|     Billy|   Bonder|\n","|         5|    Ayoung|  Atiches|         5|     Brian|    Black|\n","+----------+----------+---------+----------+----------+---------+\n","\n"]}],"source":["data1.join(data2, data1.subject_id==data2.subject_id,\"inner\").show()"]},{"cell_type":"markdown","metadata":{"id":"On7M4MojRqXv"},"source":["### Step 9. Merge all values in data1 and data2, with matching records from both sides where available."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BoU6wnN0RqXv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712843709515,"user_tz":-120,"elapsed":2103,"user":{"displayName":"Ki","userId":"11929899752149255490"}},"outputId":"3f02bc8f-6132-4357-de65-36f10685de04"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+----------+---------+----------+----------+---------+\n","|subject_id|first_name|last_name|subject_id|first_name|last_name|\n","+----------+----------+---------+----------+----------+---------+\n","|         1|      Alex| Anderson|      NULL|      NULL|     NULL|\n","|         2|       Amy| Ackerman|      NULL|      NULL|     NULL|\n","|         3|     Allen|      Ali|      NULL|      NULL|     NULL|\n","|         4|     Alice|     Aoni|         4|     Billy|   Bonder|\n","|         5|    Ayoung|  Atiches|         5|     Brian|    Black|\n","|      NULL|      NULL|     NULL|         6|      Bran|  Balwner|\n","|      NULL|      NULL|     NULL|         7|     Bryce|    Brice|\n","|      NULL|      NULL|     NULL|         8|     Betty|   Btisan|\n","+----------+----------+---------+----------+----------+---------+\n","\n"]}],"source":["data1.join(data2, data1.subject_id==data2.subject_id,\"outer\").show()"]},{"cell_type":"code","source":[],"metadata":{"id":"8lwSdHANcNHp"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.11"},"colab":{"provenance":[{"file_id":"https://github.com/areibman/pyspark_exercises/blob/master/05_Merge/Fictitous%20Names/Exercises.ipynb","timestamp":1712840946232}]}},"nbformat":4,"nbformat_minor":0}